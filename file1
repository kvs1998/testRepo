# app.py (Focusing only on the DT STATE tab's date filter section)

# ... (Previous code for tab_dt_state, history_df checks, and filter_cols_top)

    # --- Date Filter Section ---
    date_filter_cols = st.columns(2) # New columns for date filters

    with date_filter_cols[0]: # This column will now contain the date_input
        min_data_date = history_df['DATA_TIMESTAMP_DT'].min().date()
        max_data_date = history_df['DATA_TIMESTAMP_DT'].max().date()
        today = pd.to_datetime('today').date()

        # Determine default value and disabled state for date_input
        date_input_disabled = False
        date_range_value = (min_data_date, max_data_date) # Default to full data range

        if use_current_day: # This variable comes from the checkbox in the other column
            if today < min_data_date:
                st.warning(f"No data available for today ({today}). Showing data up to {max_data_date}.")
                date_range_value = (max_data_date, max_data_date)
                date_input_disabled = True
            elif today > max_data_date:
                st.warning(f"No data available for today ({today}). Showing data up to {max_data_date}.")
                date_range_value = (max_data_date, max_data_date)
                date_input_disabled = True
            else:
                date_range_value = (today, today)
                date_input_disabled = True

        date_range = st.date_input(
            "Select Data Timestamp Range:",
            value=date_range_value,
            min_value=min_data_date,
            max_value=max_data_date,
            key="date_range_filter",
            disabled=date_input_disabled
        )

    with date_filter_cols[1]: # This column will now contain the checkbox
        st.write("") # Spacer to align the checkbox visually
        use_current_day = st.checkbox("Show Current Day Only", key="current_day_checkbox")


    # --- Apply all filters to filtered_history_df ---
    # ... (rest of the filter application logic, which remains the same)



# app.py
import streamlit as st
import pandas as pd
import plotly.express as px

# Import the functions from your module
import snowflake_data # Assuming your module is saved as snowflake_data.py

st.set_page_config(layout="wide")

st.title("Dynamic Table Refresh Status Dashboard")

# Define the tabs
tab1, tab_dt_state, tab3 = st.tabs(["Overview", "DT STATE", "Product Analysis"]) # Renamed tab1, added DT STATE

# --- Fetch the cached raw data once, outside of any specific tab ---
# This ensures all tabs can access the data, and it's cached once.
history_df = snowflake_data.get_dt_refresh_history()

# --- Tab 1: Overview (Simplified) ---
with tab1:
    st.header("Overall Dashboard Overview")

    if not history_df.empty:
        # Display key refresh status metrics here, as they are a high-level overview
        st.subheader("Key Refresh Status Summary (All Tables)")
        state_counts_kpi = history_df['STATE'].value_counts()
        total_tables_kpi = state_counts_kpi.sum()

        col_failed_kpi, col_succeeded_kpi, col_executing_kpi = st.columns(3)

        with col_failed_kpi:
            failed_count_kpi = state_counts_kpi.get("FAILED", 0) + state_counts_kpi.get("UPSTREAM_FAILED", 0)
            st.metric(label="<span style='color:red;'>Total Failed/Upstream Failed</span>",
                      value=f"{failed_count_kpi} tables",
                      delta=f"{failed_count_kpi/total_tables_kpi:.1%}" if total_tables_kpi > 0 else "0.0%",
                      delta_color="inverse")

        with col_succeeded_kpi:
            succeeded_count_kpi = state_counts_kpi.get("SUCCEEDED", 0)
            st.metric(label="<span style='color:green;'>Succeeded</span>",
                      value=f"{succeeded_count_kpi} tables",
                      delta=f"{succeeded_count_kpi/total_tables_kpi:.1%}" if total_tables_kpi > 0 else "0.0%",
                      delta_color="normal")

        with col_executing_kpi:
            executing_count_kpi = state_counts_kpi.get("EXECUTING", 0)
            st.metric(label="<span style='color:purple;'>Executing</span>",
                      value=f"{executing_count_kpi} tables")

        st.divider()

        # You might put a simple bar chart of overall state distribution here too
        st.subheader("Overall Distribution of Dynamic Table States")
        state_counts = history_df['STATE'].value_counts().reset_index()
        state_counts.columns = ['STATE', 'COUNT']
        state_order = ["FAILED", "UPSTREAM_FAILED", "CANCELLED", "SCHEDULED", "EXECUTING", "SUCCEEDED"]
        state_counts['STATE'] = pd.Categorical(state_counts['STATE'], categories=state_order, ordered=True)
        state_counts = state_counts.sort_values('STATE')
        fig_bar_states = px.bar(state_counts,
                                 x='COUNT', y='STATE', orientation='h',
                                 title='Total Tables per Refresh State',
                                 color='STATE',
                                 color_discrete_map={
                                     "FAILED": "red", "UPSTREAM_FAILED": "darkred", "CANCELLED": "orange",
                                     "SCHEDULED": "blue", "EXECUTING": "purple", "SUCCEEDED": "green"
                                 })
        fig_bar_states.update_layout(showlegend=False)
        fig_bar_states.update_yaxes(categoryorder="array", categoryarray=state_counts['STATE'].tolist()[::-1])
        st.plotly_chart(fig_bar_states, use_container_width=True)


    else:
        st.warning("No data loaded from Snowflake. Cannot display overview.")


# --- Tab "DT STATE": Dedicated Dynamic Table State Analysis ---
with tab_dt_state:
    st.header("Dynamic Table Refresh History & Analysis")

    if not history_df.empty:
        # Ensure DATA_TIMESTAMP is datetime for filtering
        history_df['DATA_TIMESTAMP_DT'] = pd.to_datetime(history_df['DATA_TIMESTAMP'])

        # --- Filtering Controls for Stacked Bar Chart ---
        st.subheader("Filter Table Refresh History:")
        filter_cols = st.columns([1, 1, 1, 0.7]) # Distribute space for filters

        with filter_cols[0]:
            # Filter by DATABASE_NAME
            all_databases = ['All'] + sorted(history_df['DATABASE_NAME'].unique().tolist())
            selected_database = st.selectbox(
                "Filter by Database:",
                options=all_databases,
                key="db_filter"
            )

        with filter_cols[1]:
            # Filter by SCHEMA_NAME (dependent on selected_database)
            if selected_database != 'All':
                schemas_in_db = ['All'] + sorted(history_df[history_df['DATABASE_NAME'] == selected_database]['SCHEMA_NAME'].unique().tolist())
            else:
                schemas_in_db = ['All'] + sorted(history_df['SCHEMA_NAME'].unique().tolist())

            selected_schema = st.selectbox(
                "Filter by Schema:",
                options=schemas_in_db,
                key="schema_filter"
            )

        # Initialize filtered_history_df based on DB and Schema filters
        filtered_history_df = history_df.copy()
        if selected_database != 'All':
            filtered_history_df = filtered_history_df[filtered_history_df['DATABASE_NAME'] == selected_database]
        if selected_schema != 'All':
            filtered_history_df = filtered_history_df[filtered_history_df['SCHEMA_NAME'] == selected_schema]


        with filter_cols[2]:
            # Filter by STATE (Multi-Select)
            all_states = sorted(history_df['STATE'].unique().tolist()) # Use full history_df for all possible states
            selected_states = st.multiselect(
                "Select States to Display:",
                options=all_states,
                default=all_states, # Show all by default
                help="Select which refresh states to include in the stacked bar chart.",
                key="state_multi_select"
            )

        with filter_cols[3]:
            # Toggle to show only problematic tables (persists even if they succeeded later)
            st.write("") # Spacer
            show_problem_tables_only = st.checkbox(
                "Show only tables with past FAILED/UPSTREAM_FAILED states",
                key="problem_tables_checkbox"
            )

        # Apply remaining filters to filtered_history_df
        # Date Range Filter
        min_date = history_df['DATA_TIMESTAMP_DT'].min().date()
        max_date = history_df['DATA_TIMESTAMP_DT'].max().date()
        date_range = st.date_input(
            "Select Data Timestamp Range:",
            value=(min_date, max_date),
            min_value=min_date,
            max_value=max_date,
            key="date_range_filter"
        )

        if len(date_range) == 2:
            start_date = pd.to_datetime(date_range[0])
            end_date = pd.to_datetime(date_range[1]) + pd.Timedelta(days=1) # Include whole end day
            filtered_history_df = filtered_history_df[
                (filtered_history_df['DATA_TIMESTAMP_DT'] >= start_date) &
                (filtered_history_df['DATA_TIMESTAMP_DT'] < end_date)
            ]

        # Apply state filter
        if selected_states:
            filtered_history_df = filtered_history_df[filtered_history_df['STATE'].isin(selected_states)]
        else:
            st.warning("Please select at least one state to display data.")
            filtered_history_df = pd.DataFrame() # Clear df if no states selected

        # Apply problem tables filter
        if show_problem_tables_only:
            # Need to check problem tables on the original history_df, then filter filtered_history_df
            problem_tables_all_time = history_df[history_df['STATE'].isin(["FAILED", "UPSTREAM_FAILED"])]['TABLE_NAME'].unique()
            if problem_tables_all_time.size > 0:
                filtered_history_df = filtered_history_df[filtered_history_df['TABLE_NAME'].isin(problem_tables_all_time)]
            else:
                st.info("No tables with FAILED/UPSTREAM_FAILED history found in the full dataset for this filter.")
                filtered_history_df = pd.DataFrame()


        st.divider() # Separator between filters and chart

        # --- Cumulative State Counts per Table (Horizontal Stacked Bar Chart) ---
        st.subheader("Historical State Counts per Table")
        st.write("This chart shows the historical count of each state for individual tables, based on applied filters.")

        if not filtered_history_df.empty:
            # Group by TABLE_NAME and STATE, then count occurrences
            table_state_counts = filtered_history_df.groupby(['TABLE_NAME', 'STATE']).size().reset_index(name='COUNT')

            # Pivot the table to have states as columns for stacking
            pivot_df = table_state_counts.pivot_table(index='TABLE_NAME',
                                                    columns='STATE',
                                                    values='COUNT').fillna(0).reset_index()

            # Ensure all possible states are present as columns (even if 0)
            all_possible_states = ["SCHEDULED", "EXECUTING", "SUCCEEDED", "FAILED", "CANCELLED", "UPSTREAM_FAILED"]
            for state in all_possible_states:
                if state not in pivot_df.columns:
                    pivot_df[state] = 0

            # Define the order for stacking based on selected_states
            stack_order_for_plot = [s for s in all_possible_states if s in selected_states]
            if not stack_order_for_plot:
                st.info("No states selected to display in the stacked bar chart. Please adjust 'Select States to Display' filter.")
                pivot_df = pd.DataFrame() # Clear pivot_df if no states selected

            if not pivot_df.empty:
                # Sort the tables for better presentation (e.g., by total fails or total refreshes)
                pivot_df['TOTAL_REFRESHES'] = pivot_df[all_possible_states].sum(axis=1) # Sum all states, even if not plotted
                pivot_df['FAILED_COUNT_FOR_SORT'] = pivot_df['FAILED'] + pivot_df['UPSTREAM_FAILED'] # Combined failed for sorting
                pivot_df = pivot_df.sort_values(by=['FAILED_COUNT_FOR_SORT', 'TOTAL_REFRESHES'], ascending=[False, False])

                # Slider for "Top N" tables displayed in the chart
                num_top_tables = st.slider(
                    "Show Top N Tables (by FAILED/UPSTREAM_FAILED then Total Refreshes):",
                    min_value=5,
                    max_value=min(100, len(pivot_df)), # Allow up to 100 bars for very large datasets
                    value=min(25, len(pivot_df)),      # Default to 25
                    key="state_history_table_slider"
                )
                display_pivot_df = pivot_df.head(num_top_tables)

                # Get the ordered list of table names for y-axis category array
                ordered_table_names = display_pivot_df['TABLE_NAME'].tolist()


                fig_table_states = px.bar(display_pivot_df,
                                          x=stack_order_for_plot, # Use the filtered stack order for x-axis
                                          y='TABLE_NAME',
                                          orientation='h',
                                          title=f'Historical State Counts for Top {num_top_tables} Tables (Filtered)',
                                          labels={
                                              'value': 'Count',
                                              'TABLE_NAME': 'Table Name',
                                              'variable': 'State'
                                          },
                                          color_discrete_map={
                                              "FAILED": "red",
                                              "UPSTREAM_FAILED": "darkred",
                                              "CANCELLED": "orange",
                                              "SCHEDULED": "blue",
                                              "EXECUTING": "purple",
                                              "SUCCEEDED": "green"
                                          },
                                          hover_name='TABLE_NAME'
                                          )

                fig_table_states.update_layout(barmode='stack', showlegend=True, height=600) # Increased height for more tables
                fig_table_states.update_yaxes(categoryorder='array', categoryarray=ordered_table_names)
                st.plotly_chart(fig_table_states, use_container_width=True)

            else:
                st.info("No data to display in the cumulative state counts chart after filtering.")
        else:
            st.info("No data available for the cumulative state counts chart after applying filters.")

    else:
        st.warning("No data loaded from Snowflake. Cannot display DT STATE analysis.")


# --- Tab 3: Product Analysis (as before) ---
with tab3:
    st.header("Product Performance Analysis")
    st.write("Analyze individual product performance and profitability.")
    df_tab3 = pd.DataFrame({
        "Product_ID": [f"P{i:03d}" for i in range(1, 11)],
        "Units_Sold": np.random.randint(50, 500, 10),
        "Revenue": np.random.randint(1000, 10000, 10)
    })
    st.dataframe(df_tab3)
    fig_tab3 = px.scatter(df_tab3, x="Units_Sold", y="Revenue", size="Units_Sold",
                          hover_name="Product_ID", title="Units Sold vs Revenue per Product")
    st.plotly_chart(fig_tab3, use_container_width=True)
