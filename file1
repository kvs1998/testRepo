# app.py
import streamlit as st
import pandas as pd
import plotly.express as px

# Import the functions from your module
import snowflake_data # Assuming your module is saved as snowflake_data.py

st.set_page_config(layout="wide")

st.title("My Multi-Chart Dashboard")

tab1, tab2, tab3 = st.tabs(["Overview Charts", "Detailed Sales", "Product Analysis"])

with tab1:
    st.header("Overall Performance (Tab 1)")

    # Fetch the cached raw data once
    history_df = snowflake_data.get_dt_refresh_history()

    # --- Filtering Controls for Stacked Bar Chart ---
    st.subheader("Filter Table Refresh History")
    filter_col1, filter_col2, filter_col3 = st.columns([1, 1, 0.5]) # Added a third smaller column for checkbox

    # Initialize filtered_history_df
    filtered_history_df = history_df.copy()

    if not history_df.empty:
        with filter_col1:
            # Filter by STATE
            all_states = sorted(history_df['STATE'].unique().tolist())
            selected_states = st.multiselect(
                "Select States to Display:",
                options=all_states,
                default=all_states, # Show all by default
                help="Select which refresh states to include in the charts."
            )

        with filter_col2:
            # Date Range Filter for Data_Timestamp
            # Ensure DATA_TIMESTAMP is datetime for min/max
            history_df['DATA_TIMESTAMP_DT'] = pd.to_datetime(history_df['DATA_TIMESTAMP'])
            min_date = history_df['DATA_TIMESTAMP_DT'].min().date()
            max_date = history_df['DATA_TIMESTAMP_DT'].max().date()
            date_range = st.date_input(
                "Select Data Timestamp Range:",
                value=(min_date, max_date),
                min_value=min_date,
                max_value=max_date
            )
            # Apply date range filter
            if len(date_range) == 2:
                start_date = pd.to_datetime(date_range[0])
                end_date = pd.to_datetime(date_range[1]) + pd.Timedelta(days=1) # Include whole end day
                filtered_history_df = filtered_history_df[
                    (filtered_history_df['DATA_TIMESTAMP_DT'] >= start_date) &
                    (filtered_history_df['DATA_TIMESTAMP_DT'] < end_date)
                ]

        with filter_col3:
            # Toggle to show only problematic tables (persists even if they succeeded later)
            st.write("") # Spacer
            st.write("") # Spacer to align checkbox
            show_problem_tables_only = st.checkbox(
                "Show only tables with past FAILED/UPSTREAM_FAILED states"
            )
            if show_problem_tables_only:
                problem_tables = history_df[history_df['STATE'].isin(["FAILED", "UPSTREAM_FAILED"])]['TABLE_NAME'].unique()
                if problem_tables.size > 0:
                    filtered_history_df = filtered_history_df[filtered_history_df['TABLE_NAME'].isin(problem_tables)]
                else:
                    st.info("No tables with FAILED/UPSTREAM_FAILED history found in the full dataset for this filter.")
                    filtered_history_df = pd.DataFrame() # Clear df if no problem tables match this filter

        # Apply state filter last, after date and problem table filtering
        if selected_states:
            filtered_history_df = filtered_history_df[filtered_history_df['STATE'].isin(selected_states)]
        else:
            st.warning("Please select at least one state to display data in the charts below.")
            filtered_history_df = pd.DataFrame() # Clear df if no states selected
    else:
        st.warning("No data loaded from Snowflake. Cannot apply filters or display charts.")


    # --- Start of the two columns section (using filtered_history_df) ---
    colA, colB = st.columns(2)

    with colA:
        st.subheader("Tables per Database (Pie Chart)")
        st.info("Note: This chart aggregates by database. Too many databases will be unreadable.")

        if not filtered_history_df.empty:
            # Aggregate by DATABASE_NAME for the pie chart
            pie_data_source = filtered_history_df.groupby('DATABASE_NAME')['TABLE_NAME'].nunique().reset_index()
            pie_data_source.rename(columns={'TABLE_NAME': 'TABLE_COUNT'}, inplace=True)

            if not pie_data_source.empty:
                fig_pie_schemas = px.pie(pie_data_source,
                                         values='TABLE_COUNT',
                                         names='DATABASE_NAME', # Use DATABASE_NAME for primary grouping in pie
                                         title='Number of Tables per Database',
                                         hole=0.3,
                                         labels={
                                             'TABLE_COUNT': 'Table Count',
                                             'DATABASE_NAME': 'Database Name'
                                         })
                fig_pie_schemas.update_traces(textposition='inside', textinfo='percent+label')
                st.plotly_chart(fig_pie_schemas, use_container_width=True)
            else:
                st.info("No data for tables per database pie chart after filtering.")
        else:
            st.info("No data available for charts after applying filters.")

    with colB:
        st.subheader("Average Refresh Time per Schema")
        if not filtered_history_df.empty:
            avg_refresh_time_df = snowflake_data.calculate_average_refresh_time(filtered_history_df)
            avg_refresh_time_df['DB_SCHEMA'] = avg_refresh_time_df['DATABASE_NAME'] + '.' + avg_refresh_time_df['SCHEMA_NAME']

            avg_refresh_time_df = avg_refresh_time_df.sort_values('REFRESH_DURATION', ascending=False)

            num_top_avg_schemas = st.slider(
                "Show Top N Schemas (Avg Refresh)",
                min_value=5,
                max_value=min(20, len(avg_refresh_time_df)),
                value=min(10, len(avg_refresh_time_df)),
                key="avg_refresh_slider"
            )
            display_avg_refresh_df = avg_refresh_time_df.head(num_top_avg_schemas)

            if not display_avg_refresh_df.empty:
                fig_bar_avg_refresh = px.bar(display_avg_refresh_df,
                                             x='REFRESH_DURATION',
                                             y='DB_SCHEMA',
                                             orientation='h',
                                             title=f'Top {num_top_avg_schemas} Schemas by Average Refresh Duration (seconds)',
                                             labels={
                                                 'REFRESH_DURATION': 'Avg. Duration (s)',
                                                 'DB_SCHEMA': 'Database.Schema'
                                             })
                fig_bar_avg_refresh.update_yaxes(categoryorder='total ascending')
                st.plotly_chart(fig_bar_avg_refresh, use_container_width=True)
            else:
                st.info("No data for average refresh time chart after filtering.")
        else:
            st.info("No data available for charts after applying filters.")

    st.divider() # Separator after the two columns

    # --- Horizontal section below the columns: Cumulative State Counts per Table ---
    st.header("Cumulative State Counts per Table")
    st.write("This chart shows the historical count of each state for individual tables, based on applied filters.")

    if not filtered_history_df.empty:
        # Group by TABLE_NAME and STATE, then count occurrences
        table_state_counts = filtered_history_df.groupby(['TABLE_NAME', 'STATE']).size().reset_index(name='COUNT')

        # Pivot the table to have states as columns for stacking
        pivot_df = table_state_counts.pivot_table(index='TABLE_NAME',
                                                columns='STATE',
                                                values='COUNT').fillna(0).reset_index()

        # Ensure all states are present as columns, even if all tables don't have them
        all_possible_states = ["SCHEDULED", "EXECUTING", "SUCCEEDED", "FAILED", "CANCELLED", "UPSTREAM_FAILED"]
        for state in all_possible_states:
            if state not in pivot_df.columns:
                pivot_df[state] = 0

        # Define the order for stacking (only states present in the filtered data will be in x-axis)
        # Use a list comprehension to ensure only selected_states are used for x-axis if filter applies
        stack_order_for_plot = [s for s in all_possible_states if s in selected_states]
        if not stack_order_for_plot:
            st.info("No states selected to display in the stacked bar chart.")
            pivot_df = pd.DataFrame() # Clear pivot_df if no states selected

        if not pivot_df.empty:
            # Sort the tables for better presentation (e.g., by total fails or total refreshes)
            pivot_df['TOTAL_REFRESHES'] = pivot_df[all_possible_states].sum(axis=1) # Summing all states, even if not plotted
            pivot_df = pivot_df.sort_values(by=['FAILED', 'TOTAL_REFRESHES'], ascending=[False, False])

            # Filter for top N tables if there are hundreds to avoid an unreadable chart
            num_top_tables = st.slider(
                "Show Top N Tables by Total Refreshes (for State History)",
                min_value=5,
                max_value=min(50, len(pivot_df)),
                value=min(20, len(pivot_df)),
                key="state_history_table_slider"
            )
            display_pivot_df = pivot_df.head(num_top_tables)

            ordered_table_names = display_pivot_df['TABLE_NAME'].tolist()


            fig_table_states = px.bar(display_pivot_df,
                                      x=stack_order_for_plot, # Use the filtered stack order for x-axis
                                      y='TABLE_NAME',
                                      orientation='h',
                                      title=f'Historical State Counts for Top {num_top_tables} Tables (Filtered)',
                                      labels={
                                          'value': 'Count',
                                          'TABLE_NAME': 'Table Name',
                                          'variable': 'State'
                                      },
                                      color_discrete_map={
                                          "FAILED": "red",
                                          "UPSTREAM_FAILED": "darkred",
                                          "CANCELLED": "orange",
                                          "SCHEDULED": "blue",
                                          "EXECUTING": "purple",
                                          "SUCCEEDED": "green"
                                      },
                                      hover_name='TABLE_NAME'
                                      )

            fig_table_states.update_layout(barmode='stack', showlegend=True)
            fig_table_states.update_yaxes(categoryorder='array', categoryarray=ordered_table_names)
            st.plotly_chart(fig_table_states, use_container_width=True)

        else:
            st.info("No data to display in the cumulative state counts chart after filtering.")
    else:
        st.info("No data available for charts after applying filters.")

    # --- Horizontal section below the columns: Distribution of Dynamic Table States ---
    st.header("Overall Distribution of Dynamic Table States")
    st.write("This chart shows the total count for each state across all tables, based on applied filters.")

    if not filtered_history_df.empty:
        state_counts = filtered_history_df['STATE'].value_counts().reset_index()
        state_counts.columns = ['STATE', 'COUNT']

        state_order = ["FAILED", "UPSTREAM_FAILED", "CANCELLED", "SCHEDULED", "EXECUTING", "SUCCEEDED"]
        # Ensure only relevant states are ordered
        state_counts['STATE'] = pd.Categorical(state_counts['STATE'], categories=[s for s in state_order if s in state_counts['STATE'].unique()], ordered=True)
        state_counts = state_counts.sort_values('STATE')

        fig_bar_states = px.bar(state_counts,
                                 x='COUNT',
                                 y='STATE',
                                 orientation='h',
                                 title='Number of Tables per Refresh State (Filtered)',
                                 color='STATE',
                                 color_discrete_map={
                                     "FAILED": "red",
                                     "UPSTREAM_FAILED": "darkred",
                                     "CANCELLED": "orange",
                                     "SCHEDULED": "blue",
                                     "EXECUTING": "purple",
                                     "SUCCEEDED": "green"
                                 })
        fig_bar_states.update_layout(showlegend=False)
        fig_bar_states.update_yaxes(categoryorder="array", categoryarray=state_counts['STATE'].tolist()[::-1])
        st.plotly_chart(fig_bar_states, use_container_width=True)
    else:
        st.info("No data to display overall state distribution after filtering.")

    st.subheader("Key Refresh Status Summary (for quick glance)")
    if not filtered_history_df.empty:
        state_counts_kpi = filtered_history_df['STATE'].value_counts()
        total_tables_kpi = state_counts_kpi.sum()

        col_failed_kpi, col_succeeded_kpi, col_executing_kpi = st.columns(3)

        with col_failed_kpi:
            failed_count_kpi = state_counts_kpi.get("FAILED", 0) + state_counts_kpi.get("UPSTREAM_FAILED", 0)
            st.metric(label="<span style='color:red;'>Total Failed/Upstream Failed</span>",
                      value=f"{failed_count_kpi} tables",
                      delta=f"{failed_count_kpi/total_tables_kpi:.1%}" if total_tables_kpi > 0 else "0.0%",
                      delta_color="inverse")

        with col_succeeded_kpi:
            succeeded_count_kpi = state_counts_kpi.get("SUCCEEDED", 0)
            st.metric(label="<span style='color:green;'>Succeeded</span>",
                      value=f"{succeeded_count_kpi} tables",
                      delta=f"{succeeded_count_kpi/total_tables_kpi:.1%}" if total_tables_kpi > 0 else "0.0%",
                      delta_color="normal")

        with col_executing_kpi:
            executing_count_kpi = state_counts_kpi.get("EXECUTING", 0)
            st.metric(label="<span style='color:purple;'>Executing</span>",
                      value=f"{executing_count_kpi} tables")

    else:
        st.info("No data for KPI summary after filtering.")


with tab2:
    st.header("Sales Breakdown by Region")
    st.write("Here you can see a more detailed breakdown of sales figures.")
    # Existing content for tab2

with tab3:
    st.header("Product Performance Analysis")
    st.write("Analyze individual product performance and profitability.")
    # Existing content for tab3
