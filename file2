# snowflake_data.py
import streamlit as st
from snowflake.snowpark import Session
import pandas as pd
import json # Import json for parsing variant

@st.cache_resource
def get_snowflake_session():
    """Establishes and caches the Snowflake session."""
    sf_config = st.secrets["snowflake_dev"]
    session = Session.builder.configs(sf_config).create()
    return session

session = get_snowflake_session() # Get the cached session

@st.cache_data
def get_dt_refresh_history():
    """
    Fetches the full refresh history data from Snowflake.
    This should be your primary cached data extraction point.
    """
    st.info("Fetching refresh history from Snowflake...")
    hist_df = session.sql(f"""
        SELECT
            DATABASE_NAME,
            SCHEMA_NAME,
            TABLE_NAME,
            STATE,
            STATE_CODE,
            STATE_MESSAGE,
            QUERY_ID,
            DATA_TIMESTAMP,
            REFRESH_START_TIME,
            REFRESH_END_TIME,
            COMPLETITION_TARGET,
            STATISTICS, -- This is the VARIANT column
            REFERSH_ACTION, -- Renamed to REFRESH_ACTION for clarity in app
            REFRESH_TRIGGER,
            TARGET_LAG_SEC
        FROM db_name.schema_name.T_DT_REFRESH_HISTORY
    """).to_pandas()
    # Ensure REFRESH_ACTION column has the correct name (if it's REFERSH_ACTION in DB)
    if 'REFERSH_ACTION' in hist_df.columns:
        hist_df.rename(columns={'REFERSH_ACTION': 'REFRESH_ACTION'}, inplace=True)

    return hist_df

# New function to parse the STATISTICS VARIANT
@st.cache_data
def parse_refresh_statistics(df: pd.DataFrame) -> pd.DataFrame:
    """
    Parses the 'STATISTICS' VARIANT column and extracts numerical properties.
    Returns a new DataFrame with original columns + extracted statistics.
    """
    if 'STATISTICS' not in df.columns or df.empty:
        return df # Return original df if no STATISTICS column or empty

    # Define the statistics properties we want to extract
    stats_properties = [
        'numInsertedRows', 'numDeletedRows', 'numCopiedRows',
        'numAddedPartitions', 'numRemovedPartitions'
    ]
    # Rename to more user-friendly capitalized names for plotting
    plot_stat_names = {
        'numInsertedRows': 'Inserted Rows',
        'numDeletedRows': 'Deleted Rows',
        'numCopiedRows': 'Copied Rows',
        'numAddedPartitions': 'Added Partitions',
        'numRemovedPartitions': 'Removed Partitions'
    }

    # Create a copy to avoid SettingWithCopyWarning
    df_copy = df.copy()

    # Function to safely parse JSON and extract property
    def get_stat_value(stat_json, prop):
        if pd.isna(stat_json):
            return 0
        try:
            stats_dict = json.loads(stat_json)
            return stats_dict.get(prop, 0)
        except json.JSONDecodeError:
            return 0 # Handle malformed JSON

    # Apply the parsing for each property
    for prop in stats_properties:
        df_copy[plot_stat_names[prop]] = df_copy['STATISTICS'].apply(lambda x: get_stat_value(x, prop))

    return df_copy


# ... (calculate_table_counts_per_schema_db and calculate_average_refresh_time functions remain)
